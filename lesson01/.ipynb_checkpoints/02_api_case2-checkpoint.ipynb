{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6082aa5",
   "metadata": {},
   "source": [
    "## 02_api_case2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2c47bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 初始環境設定\n",
    "import os\n",
    "from pathlib import Path\n",
    "HOME = str(Path.home())\n",
    "Add_Binarry_Path=HOME+'/.local/bin'\n",
    "os.environ['PATH']=os.environ['PATH']+':'+Add_Binarry_Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754690fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PIP\n",
    "!pip install hf_transfer openai\n",
    "#!pip install hf_transfer langchain langchain-openai openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b959ebab",
   "metadata": {},
   "source": [
    "## OPENAI EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ce3a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## QA normal 1\n",
    "\n",
    "## OPENAI KEY\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "  api_key = \"nvapi-\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  #model=\"nvidia/nemotron-4-340b-instruct\",\n",
    "  model=\"microsoft/phi-3-medium-4k-instruct\",    \n",
    "  messages=[{\"role\":\"user\",\"content\":\"請介紹五樣台灣小吃\"}],\n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec7e2b4",
   "metadata": {},
   "source": [
    "## OPENAI EXAMPLE PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "530cc0a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarize the text delimited by triple backticks \\ \n",
      "into a single sentence.\n",
      "```\n",
      "You should express what you want a model to do by \\ \n",
      "providing instructions that are as clear and \\ \n",
      "specific as you can possibly make them. \\ \n",
      "This will guide the model towards the desired output, \\ \n",
      "and reduce the chances of receiving irrelevant \\ \n",
      "or incorrect responses. Don't confuse writing a \\ \n",
      "clear prompt with writing a short prompt. \\ \n",
      "In many cases, longer prompts provide more clarity \\ \n",
      "and context for the model, which can lead to \\ \n",
      "more detailed and relevant outputs.\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140958e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## QA normal 2\n",
    "\n",
    "## OPENAI KEY\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "  api_key = \"nvapi-\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  #model=\"nvidia/nemotron-4-340b-instruct\",\n",
    "  model=\"microsoft/phi-3-medium-4k-instruct\",    \n",
    "  messages=[{\"role\":\"user\",\"content\":prompt}],\n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58e9ddbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "What is the sentiment of the following product review, \n",
      "which is delimited with triple backticks?\n",
      "\n",
      "Review text: '''\n",
      "Needed a nice lamp for my bedroom, and this one had additional storage and not too high of a price point. Got it fast.  The string to our lamp broke during the transit and the company happily sent over a new one. Came within a few days as well. It was easy to put together.  I had a missing part, so I contacted their support and they very quickly got me the missing piece! Lumina seems to me to be a great company that cares abo\n",
      "ut their customers and products!!\n",
      "'''\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lamp_review = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one had \\\n",
    "additional storage and not too high of a price point. \\\n",
    "Got it fast.  The string to our lamp broke during the \\\n",
    "transit and the company happily sent over a new one. \\\n",
    "Came within a few days as well. It was easy to put \\\n",
    "together.  I had a missing part, so I contacted their \\\n",
    "support and they very quickly got me the missing piece! \\\n",
    "Lumina seems to me to be a great company that cares \\\n",
    "abo\n",
    "ut their customers and products!!\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review, \n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cc95df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the product review is positive. The reviewer expresses satisfaction with the lamp's features, price, and delivery speed. They also appreciate the company's customer service and responsiveness in addressing issues such as the broken string and missing part. Overall, the reviewer has a favorable impression of the product and the company.\n"
     ]
    }
   ],
   "source": [
    "## QA normal 2\n",
    "\n",
    "## OPENAI KEY\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "  api_key = \"nvapi-\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  #model=\"nvidia/nemotron-4-340b-instruct\",\n",
    "  model=\"microsoft/phi-3-medium-4k-instruct\",    \n",
    "  messages=[{\"role\":\"user\",\"content\":prompt}],\n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7668c0b",
   "metadata": {},
   "source": [
    "## QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52b7d934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': '您是一個合成問答配對生成器。依據<SOURCE> 和 </SOURCE>之間的內容，生成 3 個示例問題，用戶可以提出這些問題，並且可以通過這段內容中的信息進行回答。例如，如果給定的內容是維基百科關於台灣的一段文字，一個示例問題可以是“台灣有多少個縣？”。這些示例問題的答案要很簡短或是幾個字。您的回覆中只需包含問題即可，並每一個回答放置於 <QUESTION> 和 </QUESTION> 之中。'}, {'role': 'user', 'content': '\\n<SOURCE>\\n2024 HPCxAI Winter Camp\\n高速運算及人工智慧課程廣受好評！\\n由國家高速網路與計算中心與國立清華大學合辦之2024 HPCxAI Winter Camp，\\n1/27-29 三天聚集國內最優秀的產學研資源，\\n透過真實操作超級電腦和接觸實際應用，\\n傳授平行程式設計和效能分析經驗。\\n培養學員（高中及大專院校生）認識與運用高速運算知識在 AI 的應用能力！\\n完整活動記錄不容錯過。   \\n</SOURCE>\\n'}]\n"
     ]
    }
   ],
   "source": [
    "chunk=f\"\"\"\n",
    "<SOURCE>\n",
    "2024 HPCxAI Winter Camp\n",
    "高速運算及人工智慧課程廣受好評！\n",
    "由國家高速網路與計算中心與國立清華大學合辦之2024 HPCxAI Winter Camp，\n",
    "1/27-29 三天聚集國內最優秀的產學研資源，\n",
    "透過真實操作超級電腦和接觸實際應用，\n",
    "傳授平行程式設計和效能分析經驗。\n",
    "培養學員（高中及大專院校生）認識與運用高速運算知識在 AI 的應用能力！\n",
    "完整活動記錄不容錯過。   \n",
    "</SOURCE>\n",
    "\"\"\"\n",
    "\n",
    "num_q=3 \n",
    "\n",
    "messages_q = [\n",
    "    {\"role\": \"system\", \"content\": f\"您是一個合成問答配對生成器。依據<SOURCE> 和 </SOURCE>之間的內容，生成 {num_q} 個示例問題，用戶可以提出這些問題，並且可以通過這段內容中的信息進行回答。例如，如果給定的內容是維基百科關於台灣的一段文字，一個示例問題可以是“台灣有多少個縣？”。這些示例問題的答案要很簡短或是幾個字。您的回覆中只需包含問題即可，並每一個回答放置於 <QUESTION> 和 </QUESTION> 之中。\"},     \n",
    "    {\"role\": \"user\", \"content\": str(chunk)}\n",
    "]\n",
    "\n",
    "print(messages_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffe5316c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<QUESTION>2024 HPCxAI Winter Camp的日期是什麼時候？</QUESTION>\n",
      "\n",
      "<QUESTION>2024 HPCxAI Winter Camp由哪兩個機構合辦？</QUESTION>\n",
      "\n",
      "<QUESTION>2024 HPCxAI Winter Camp的參與者是誰？</QUESTION>\n"
     ]
    }
   ],
   "source": [
    "## QA normal 2\n",
    "\n",
    "## OPENAI KEY\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "  api_key = \"nvapi-\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  #model=\"nvidia/nemotron-4-340b-instruct\",\n",
    "  model=\"microsoft/phi-3-medium-4k-instruct\",    \n",
    "  messages=messages_q,\n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a73eec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': '你是一位樂於助人的問答者，可以根據問題和相關上下文提供答案'}, {'role': 'user', 'content': '這項活動主要想培養學員哪些能力？'}, {'role': 'user', 'content': '2024 HPCxAI Winter Camp\\n高速運算及人工智慧課程廣受好評！\\n由國家高速網路與計算中心與國立清華大學合辦之2024 HPCxAI Winter Camp，\\n1/27-29 三天聚集國內最優秀的產學研資源，\\n透過真實操作超級電腦和接觸實際應用，\\n傳授平行程式設計和效能分析經驗。\\n培養學員（高中及大專院校生）認識與運用高速運算知識在 AI 的應用能力！\\n完整活動記錄不容錯過。    \\n'}, {'role': 'user', 'content': '使用上述內容中提供的資訊回答這個問題。以下是需要注意的事項：\\n首先提供逐步推理，解釋如何回答問題。\\n在推理過程中，如果需要從內容中複製粘貼一些句子，請將它們放在 <PROCESS> 和 </PROCESS> 之間。\\n最後將回答內容放置於 <ANSWER> 和 </ANSWER>之間。回答內容需要簡潔，不需要太長  \\n'}]\n"
     ]
    }
   ],
   "source": [
    "question=\"這項活動主要想培養學員哪些能力？\"\n",
    "\n",
    "content=f\"\"\"2024 HPCxAI Winter Camp\n",
    "高速運算及人工智慧課程廣受好評！\n",
    "由國家高速網路與計算中心與國立清華大學合辦之2024 HPCxAI Winter Camp，\n",
    "1/27-29 三天聚集國內最優秀的產學研資源，\n",
    "透過真實操作超級電腦和接觸實際應用，\n",
    "傳授平行程式設計和效能分析經驗。\n",
    "培養學員（高中及大專院校生）認識與運用高速運算知識在 AI 的應用能力！\n",
    "完整活動記錄不容錯過。    \n",
    "\"\"\"\n",
    "\n",
    "limit=f\"\"\"使用上述內容中提供的資訊回答這個問題。以下是需要注意的事項：\n",
    "首先提供逐步推理，解釋如何回答問題。\n",
    "在推理過程中，如果需要從內容中複製粘貼一些句子，請將它們放在 <PROCESS> 和 </PROCESS> 之間。\n",
    "最後將回答內容放置於 <ANSWER> 和 </ANSWER>之間。回答內容需要簡潔，不需要太長  \n",
    "\"\"\"\n",
    "\n",
    "messages_q = [\n",
    "    {\"role\": \"system\", \"content\": f\"你是一位樂於助人的問答者，可以根據問題和相關上下文提供答案\"},     \n",
    "    {\"role\": \"user\", \"content\": str(question)},\n",
    "    {\"role\": \"user\", \"content\": str(content)},\n",
    "    {\"role\": \"user\", \"content\": str(limit)}\n",
    "\n",
    "]\n",
    "\n",
    "print(messages_q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f6f741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PROCESS>\n",
      "1. 閱讀和分析提供的內容，以了解2024 HPCxAI Winter Camp的目標和內容。\n",
      "2. 辨識活動主要想培養學員的能力。\n",
      "3. 從內容中提取相關信息。\n",
      "</PROCESS>\n",
      "\n",
      "<ANSWER>\n",
      "2024 HPCxAI Winter Camp主要想培養學員認識與運用高速運算知識在人工智慧應用的能力。</ANSWER>\n"
     ]
    }
   ],
   "source": [
    "## QA normal 2\n",
    "\n",
    "## OPENAI KEY\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "  api_key = \"nvapi-\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  #model=\"nvidia/nemotron-4-340b-instruct\",\n",
    "  model=\"microsoft/phi-3-medium-4k-instruct\",    \n",
    "  messages=messages_q,\n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cae7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
